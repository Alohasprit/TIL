{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:16:26.148364Z",
     "start_time": "2019-01-21T04:16:21.702697Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:16:27.670227Z",
     "start_time": "2019-01-21T04:16:26.150366Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Prepare Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:16:27.928154Z",
     "start_time": "2019-01-21T04:16:27.671231Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ', 'ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
      "{'ㄱ': 0, 'ㄲ': 1, 'ㄴ': 2, 'ㄷ': 3, 'ㄸ': 4, 'ㄹ': 5, 'ㅁ': 6, 'ㅂ': 7, 'ㅃ': 8, 'ㅅ': 9, 'ㅆ': 10, 'ㅇ': 11, 'ㅈ': 12, 'ㅉ': 13, 'ㅊ': 14, 'ㅋ': 15, 'ㅌ': 16, 'ㅍ': 17, 'ㅎ': 18, 'ㅏ': 19, 'ㅐ': 20, 'ㅑ': 21, 'ㅒ': 22, 'ㅓ': 23, 'ㅔ': 24, 'ㅕ': 25, 'ㅖ': 26, 'ㅗ': 27, 'ㅘ': 28, 'ㅙ': 29, 'ㅛ': 30, 'ㅜ': 31, 'ㅝ': 32, 'ㅞ': 33, 'ㅟ': 34, 'ㅠ': 35, 'ㅡ': 36, 'ㅢ': 37, 'ㅣ': 38}\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"./data/jamo\"\n",
    "img_data = dsets.ImageFolder(img_dir, transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            ]))\n",
    "\n",
    "#https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "print(img_data.classes)\n",
    "print(img_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:16:27.932153Z",
     "start_time": "2019-01-21T04:16:27.929154Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:16:27.990160Z",
     "start_time": "2019-01-21T04:16:27.933153Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(data, train_ratio, batch_size, stratify) :\n",
    "    \n",
    "    length = len(data)\n",
    "    \n",
    "    cut = int(len(data)*train_ratio)\n",
    "    train_indices = np.random.shuffle(np.random.permutation(np.arange(length))[:cut])\n",
    "    test_indices = np.random.shuffle(np.random.permutation(np.arange(length))[cut:])\n",
    "        \n",
    "    if stratify :\n",
    "        \n",
    "        count = [0]*len(img_data.classes)\n",
    "        for _, label in img_data :\n",
    "            count[label] += 1\n",
    "\n",
    "        weight = []    \n",
    "        for i, (_, label) in enumerate(img_data) :\n",
    "            weight.append(1/ count[label])\n",
    "        weight = np.array(weight)\n",
    "        \n",
    "        train_indices = np.random.choice(length, cut, p=weight/sum(weight), replace=False)\n",
    "        test_indices = np.array(list(set(range(length)) - set(train_indices)))\n",
    "        \n",
    "    train_loader = Data.DataLoader(data, batch_size=batch_size, shuffle=False, sampler = torch.utils.data.SubsetRandomSampler(train_indices), drop_last = True)\n",
    "    test_loader = Data.DataLoader(data, batch_size=batch_size, shuffle=False, sampler = torch.utils.data.SubsetRandomSampler(test_indices), drop_last = True)\n",
    "\n",
    "    return train_loader, test_loader, len(train_indices), len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:17:02.972491Z",
     "start_time": "2019-01-21T04:16:33.884755Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader, train_num, test_num = train_test_split(img_data, 0.8, batch_size, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:17:14.123324Z",
     "start_time": "2019-01-21T04:17:14.109332Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img, title):\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.figure(figsize = (5, 15))\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:17:14.505136Z",
     "start_time": "2019-01-21T04:17:14.308203Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = iter(train_loader).next()\n",
    "imshow(torchvision.utils.make_grid(images, normalize=True), \"Train Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:17:14.670642Z",
     "start_time": "2019-01-21T04:17:14.660645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 1, 36, 36]), tensor([38, 38,  1, 30, 34]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:17:15.503921Z",
     "start_time": "2019-01-21T04:17:15.460938Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3, padding=1), # 16 * 36 * 36\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv2d(16,32,3), # 32 * 34 * 34\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv2d(32,64,3), # 64 * 32 * 32\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2,2), # 32 * 16 * 16\n",
    "            \n",
    "            nn.Conv2d(64,128,3), # 128 * 14 * 14\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2,2), # 128 * 7 * 7\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(128*7*7, 39)\n",
    "        ) \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv_layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:17:17.407023Z",
     "start_time": "2019-01-21T04:17:15.626454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_layer): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2)\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Dropout(p=0.2)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=39, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN().cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:17:17.421018Z",
     "start_time": "2019-01-21T04:17:16.343Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:17:17.434014Z",
     "start_time": "2019-01-21T04:17:17.094Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], lter [100/224], Loss: 0.0061\n",
      "Epoch [1/500], lter [200/224], Loss: 0.0041\n",
      "Epoch [2/500], lter [100/224], Loss: 0.0019\n",
      "Epoch [2/500], lter [200/224], Loss: 0.0029\n",
      "Epoch [3/500], lter [100/224], Loss: 0.0023\n",
      "Epoch [3/500], lter [200/224], Loss: 0.0015\n",
      "Epoch [4/500], lter [100/224], Loss: 0.0026\n",
      "Epoch [4/500], lter [200/224], Loss: 0.0036\n",
      "Epoch [5/500], lter [100/224], Loss: 0.0084\n",
      "Epoch [5/500], lter [200/224], Loss: 0.0028\n",
      "Epoch [6/500], lter [100/224], Loss: 0.0022\n",
      "Epoch [6/500], lter [200/224], Loss: 0.0011\n",
      "Epoch [7/500], lter [100/224], Loss: 0.0024\n",
      "Epoch [7/500], lter [200/224], Loss: 0.0023\n",
      "Epoch [8/500], lter [100/224], Loss: 0.0042\n",
      "Epoch [8/500], lter [200/224], Loss: 0.0016\n",
      "Epoch [9/500], lter [100/224], Loss: 0.0022\n",
      "Epoch [9/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [10/500], lter [100/224], Loss: 0.0031\n",
      "Epoch [10/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [11/500], lter [100/224], Loss: 0.0018\n",
      "Epoch [11/500], lter [200/224], Loss: 0.0022\n",
      "Epoch [12/500], lter [100/224], Loss: 0.0024\n",
      "Epoch [12/500], lter [200/224], Loss: 0.0023\n",
      "Epoch [13/500], lter [100/224], Loss: 0.0014\n",
      "Epoch [13/500], lter [200/224], Loss: 0.0028\n",
      "Epoch [14/500], lter [100/224], Loss: 0.0027\n",
      "Epoch [14/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [15/500], lter [100/224], Loss: 0.0019\n",
      "Epoch [15/500], lter [200/224], Loss: 0.0016\n",
      "Epoch [16/500], lter [100/224], Loss: 0.0021\n",
      "Epoch [16/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [17/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [17/500], lter [200/224], Loss: 0.0036\n",
      "Epoch [18/500], lter [100/224], Loss: 0.0030\n",
      "Epoch [18/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [19/500], lter [100/224], Loss: 0.0031\n",
      "Epoch [19/500], lter [200/224], Loss: 0.0040\n",
      "Epoch [20/500], lter [100/224], Loss: 0.0029\n",
      "Epoch [20/500], lter [200/224], Loss: 0.0018\n",
      "Epoch [21/500], lter [100/224], Loss: 0.0012\n",
      "Epoch [21/500], lter [200/224], Loss: 0.0025\n",
      "Epoch [22/500], lter [100/224], Loss: 0.0015\n",
      "Epoch [22/500], lter [200/224], Loss: 0.0027\n",
      "Epoch [23/500], lter [100/224], Loss: 0.0020\n",
      "Epoch [23/500], lter [200/224], Loss: 0.0024\n",
      "Epoch [24/500], lter [100/224], Loss: 0.0036\n",
      "Epoch [24/500], lter [200/224], Loss: 0.0031\n",
      "Epoch [25/500], lter [100/224], Loss: 0.0012\n",
      "Epoch [25/500], lter [200/224], Loss: 0.0013\n",
      "Epoch [26/500], lter [100/224], Loss: 0.0053\n",
      "Epoch [26/500], lter [200/224], Loss: 0.0014\n",
      "Epoch [27/500], lter [100/224], Loss: 0.0012\n",
      "Epoch [27/500], lter [200/224], Loss: 0.0020\n",
      "Epoch [28/500], lter [100/224], Loss: 0.0020\n",
      "Epoch [28/500], lter [200/224], Loss: 0.0034\n",
      "Epoch [29/500], lter [100/224], Loss: 0.0011\n",
      "Epoch [29/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [30/500], lter [100/224], Loss: 0.0016\n",
      "Epoch [30/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [31/500], lter [100/224], Loss: 0.0013\n",
      "Epoch [31/500], lter [200/224], Loss: 0.0018\n",
      "Epoch [32/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [32/500], lter [200/224], Loss: 0.0042\n",
      "Epoch [33/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [33/500], lter [200/224], Loss: 0.0011\n",
      "Epoch [34/500], lter [100/224], Loss: 0.0019\n",
      "Epoch [34/500], lter [200/224], Loss: 0.0016\n",
      "Epoch [35/500], lter [100/224], Loss: 0.0018\n",
      "Epoch [35/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [36/500], lter [100/224], Loss: 0.0017\n",
      "Epoch [36/500], lter [200/224], Loss: 0.0025\n",
      "Epoch [37/500], lter [100/224], Loss: 0.0021\n",
      "Epoch [37/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [38/500], lter [100/224], Loss: 0.0016\n",
      "Epoch [38/500], lter [200/224], Loss: 0.0029\n",
      "Epoch [39/500], lter [100/224], Loss: 0.0021\n",
      "Epoch [39/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [40/500], lter [100/224], Loss: 0.0015\n",
      "Epoch [40/500], lter [200/224], Loss: 0.0017\n",
      "Epoch [41/500], lter [100/224], Loss: 0.0030\n",
      "Epoch [41/500], lter [200/224], Loss: 0.0022\n",
      "Epoch [42/500], lter [100/224], Loss: 0.0026\n",
      "Epoch [42/500], lter [200/224], Loss: 0.0022\n",
      "Epoch [58/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [58/500], lter [200/224], Loss: 0.0022\n",
      "Epoch [59/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [59/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [60/500], lter [100/224], Loss: 0.0013\n",
      "Epoch [60/500], lter [200/224], Loss: 0.0016\n",
      "Epoch [61/500], lter [100/224], Loss: 0.0012\n",
      "Epoch [61/500], lter [200/224], Loss: 0.0010\n",
      "Epoch [62/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [62/500], lter [200/224], Loss: 0.0013\n",
      "Epoch [63/500], lter [100/224], Loss: 0.0036\n",
      "Epoch [63/500], lter [200/224], Loss: 0.0017\n",
      "Epoch [64/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [64/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [65/500], lter [100/224], Loss: 0.0011\n",
      "Epoch [65/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [66/500], lter [100/224], Loss: 0.0020\n",
      "Epoch [66/500], lter [200/224], Loss: 0.0016\n",
      "Epoch [67/500], lter [100/224], Loss: 0.0014\n",
      "Epoch [67/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [68/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [68/500], lter [200/224], Loss: 0.0018\n",
      "Epoch [69/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [69/500], lter [200/224], Loss: 0.0010\n",
      "Epoch [70/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [70/500], lter [200/224], Loss: 0.0011\n",
      "Epoch [71/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [71/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [72/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [72/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [73/500], lter [100/224], Loss: 0.0012\n",
      "Epoch [73/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [74/500], lter [100/224], Loss: 0.0014\n",
      "Epoch [74/500], lter [200/224], Loss: 0.0030\n",
      "Epoch [75/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [75/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [76/500], lter [100/224], Loss: 0.0017\n",
      "Epoch [76/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [77/500], lter [100/224], Loss: 0.0027\n",
      "Epoch [77/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [78/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [78/500], lter [200/224], Loss: 0.0026\n",
      "Epoch [79/500], lter [100/224], Loss: 0.0014\n",
      "Epoch [79/500], lter [200/224], Loss: 0.0011\n",
      "Epoch [80/500], lter [100/224], Loss: 0.0013\n",
      "Epoch [80/500], lter [200/224], Loss: 0.0022\n",
      "Epoch [81/500], lter [100/224], Loss: 0.0012\n",
      "Epoch [81/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [82/500], lter [100/224], Loss: 0.0011\n",
      "Epoch [82/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [83/500], lter [100/224], Loss: 0.0011\n",
      "Epoch [83/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [84/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [84/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [85/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [85/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [86/500], lter [100/224], Loss: 0.0026\n",
      "Epoch [86/500], lter [200/224], Loss: 0.0013\n",
      "Epoch [87/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [87/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [88/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [88/500], lter [200/224], Loss: 0.0037\n",
      "Epoch [89/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [89/500], lter [200/224], Loss: 0.0010\n",
      "Epoch [90/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [90/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [91/500], lter [100/224], Loss: 0.0012\n",
      "Epoch [91/500], lter [200/224], Loss: 0.0020\n",
      "Epoch [92/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [92/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [93/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [93/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [94/500], lter [100/224], Loss: 0.0009\n",
      "Epoch [94/500], lter [200/224], Loss: 0.0011\n",
      "Epoch [95/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [95/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [96/500], lter [100/224], Loss: 0.0013\n",
      "Epoch [96/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [97/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [97/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [98/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [98/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [99/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [99/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [100/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [100/500], lter [200/224], Loss: 0.0011\n",
      "Epoch [101/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [101/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [102/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [102/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [103/500], lter [100/224], Loss: 0.0040\n",
      "Epoch [103/500], lter [200/224], Loss: 0.0011\n",
      "Epoch [104/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [104/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [105/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [105/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [106/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [106/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [107/500], lter [100/224], Loss: 0.0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [108/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [108/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [109/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [109/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [110/500], lter [100/224], Loss: 0.0013\n",
      "Epoch [110/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [111/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [111/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [112/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [112/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [113/500], lter [100/224], Loss: 0.0019\n",
      "Epoch [113/500], lter [200/224], Loss: 0.0010\n",
      "Epoch [114/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [114/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [115/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [115/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [116/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [116/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [117/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [117/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [118/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [118/500], lter [200/224], Loss: 0.0013\n",
      "Epoch [119/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [119/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [120/500], lter [100/224], Loss: 0.0014\n",
      "Epoch [120/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [121/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [121/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [122/500], lter [100/224], Loss: 0.0009\n",
      "Epoch [122/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [123/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [123/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [124/500], lter [100/224], Loss: 0.0016\n",
      "Epoch [124/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [125/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [125/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [126/500], lter [100/224], Loss: 0.0009\n",
      "Epoch [126/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [127/500], lter [100/224], Loss: 0.0019\n",
      "Epoch [127/500], lter [200/224], Loss: 0.0025\n",
      "Epoch [128/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [128/500], lter [200/224], Loss: 0.0174\n",
      "Epoch [129/500], lter [100/224], Loss: 0.0009\n",
      "Epoch [129/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [130/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [130/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [131/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [131/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [132/500], lter [100/224], Loss: 0.0026\n",
      "Epoch [132/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [133/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [133/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [134/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [134/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [135/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [135/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [136/500], lter [100/224], Loss: 0.0012\n",
      "Epoch [136/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [137/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [137/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [138/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [138/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [139/500], lter [100/224], Loss: 0.0022\n",
      "Epoch [139/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [140/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [140/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [141/500], lter [100/224], Loss: 0.0011\n",
      "Epoch [141/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [142/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [142/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [143/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [143/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [144/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [144/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [145/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [145/500], lter [200/224], Loss: 0.0018\n",
      "Epoch [146/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [146/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [147/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [147/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [148/500], lter [100/224], Loss: 0.0018\n",
      "Epoch [148/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [149/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [149/500], lter [200/224], Loss: 0.0013\n",
      "Epoch [150/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [150/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [151/500], lter [100/224], Loss: 0.0012\n",
      "Epoch [151/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [152/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [152/500], lter [200/224], Loss: 0.0025\n",
      "Epoch [153/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [153/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [154/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [154/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [155/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [155/500], lter [200/224], Loss: 0.0013\n",
      "Epoch [156/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [156/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [157/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [157/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [158/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [158/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [159/500], lter [100/224], Loss: 0.0011\n",
      "Epoch [159/500], lter [200/224], Loss: 0.0011\n",
      "Epoch [160/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [160/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [161/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [161/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [162/500], lter [100/224], Loss: 0.0013\n",
      "Epoch [162/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [163/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [163/500], lter [200/224], Loss: 0.0017\n",
      "Epoch [164/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [164/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [165/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [165/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [166/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [166/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [167/500], lter [100/224], Loss: 0.0019\n",
      "Epoch [167/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [168/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [168/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [169/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [169/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [170/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [170/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [171/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [171/500], lter [200/224], Loss: 0.0013\n",
      "Epoch [172/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [172/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [173/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [173/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [174/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [174/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [175/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [175/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [176/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [176/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [177/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [177/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [178/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [178/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [179/500], lter [100/224], Loss: 0.0022\n",
      "Epoch [179/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [180/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [180/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [181/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [181/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [182/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [182/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [183/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [183/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [184/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [184/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [185/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [185/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [186/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [186/500], lter [200/224], Loss: 0.0014\n",
      "Epoch [187/500], lter [100/224], Loss: 0.0017\n",
      "Epoch [187/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [188/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [188/500], lter [200/224], Loss: 0.0010\n",
      "Epoch [189/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [189/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [190/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [190/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [191/500], lter [100/224], Loss: 0.0009\n",
      "Epoch [191/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [192/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [192/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [193/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [193/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [194/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [194/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [195/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [195/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [196/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [196/500], lter [200/224], Loss: 0.0005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [197/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [197/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [198/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [198/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [199/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [199/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [200/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [200/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [201/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [201/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [202/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [202/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [203/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [203/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [204/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [204/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [205/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [205/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [206/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [206/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [207/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [207/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [208/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [208/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [209/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [209/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [210/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [210/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [211/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [211/500], lter [200/224], Loss: 0.0021\n",
      "Epoch [212/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [212/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [213/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [213/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [214/500], lter [100/224], Loss: 0.0009\n",
      "Epoch [214/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [215/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [215/500], lter [200/224], Loss: 0.0014\n",
      "Epoch [216/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [216/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [217/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [217/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [218/500], lter [100/224], Loss: 0.0011\n",
      "Epoch [218/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [219/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [219/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [220/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [220/500], lter [200/224], Loss: 0.0012\n",
      "Epoch [221/500], lter [100/224], Loss: 0.0013\n",
      "Epoch [221/500], lter [200/224], Loss: 0.0212\n",
      "Epoch [222/500], lter [100/224], Loss: 0.0025\n",
      "Epoch [222/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [223/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [223/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [224/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [224/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [225/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [225/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [226/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [226/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [227/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [227/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [228/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [228/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [229/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [229/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [230/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [230/500], lter [200/224], Loss: 0.0011\n",
      "Epoch [231/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [231/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [232/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [232/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [233/500], lter [100/224], Loss: 0.0246\n",
      "Epoch [233/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [234/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [234/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [235/500], lter [100/224], Loss: 0.0009\n",
      "Epoch [235/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [236/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [236/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [237/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [237/500], lter [200/224], Loss: 0.0010\n",
      "Epoch [238/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [238/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [239/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [239/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [240/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [240/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [241/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [241/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [242/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [242/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [243/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [243/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [244/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [244/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [245/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [245/500], lter [200/224], Loss: 0.0014\n",
      "Epoch [246/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [246/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [247/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [247/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [248/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [264/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [264/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [265/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [265/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [266/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [266/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [267/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [267/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [268/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [268/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [269/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [269/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [270/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [270/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [271/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [271/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [272/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [272/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [273/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [273/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [274/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [274/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [275/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [275/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [276/500], lter [100/224], Loss: 0.0011\n",
      "Epoch [276/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [277/500], lter [100/224], Loss: 0.0009\n",
      "Epoch [277/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [278/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [278/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [279/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [279/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [280/500], lter [100/224], Loss: 0.0012\n",
      "Epoch [280/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [281/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [281/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [282/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [282/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [283/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [283/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [284/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [284/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [285/500], lter [100/224], Loss: 0.0009\n",
      "Epoch [285/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [286/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [286/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [287/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [287/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [288/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [288/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [289/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [289/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [290/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [290/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [291/500], lter [100/224], Loss: 0.0015\n",
      "Epoch [291/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [292/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [292/500], lter [200/224], Loss: 0.0247\n",
      "Epoch [293/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [293/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [294/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [294/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [295/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [295/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [296/500], lter [100/224], Loss: 0.0013\n",
      "Epoch [296/500], lter [200/224], Loss: 0.0011\n",
      "Epoch [297/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [297/500], lter [200/224], Loss: 0.0013\n",
      "Epoch [298/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [298/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [299/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [299/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [300/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [300/500], lter [200/224], Loss: 0.0257\n",
      "Epoch [301/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [301/500], lter [200/224], Loss: 0.0009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [302/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [302/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [303/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [303/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [304/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [304/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [305/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [305/500], lter [200/224], Loss: 0.0011\n",
      "Epoch [306/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [306/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [307/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [307/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [308/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [308/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [309/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [309/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [310/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [310/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [311/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [311/500], lter [200/224], Loss: 0.0015\n",
      "Epoch [312/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [312/500], lter [200/224], Loss: 0.0000\n",
      "Epoch [313/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [313/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [314/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [314/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [315/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [315/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [316/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [316/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [317/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [317/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [318/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [318/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [319/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [319/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [320/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [320/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [321/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [321/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [322/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [322/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [323/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [323/500], lter [200/224], Loss: 0.0009\n",
      "Epoch [324/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [324/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [325/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [325/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [326/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [326/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [327/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [327/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [328/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [328/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [329/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [329/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [330/500], lter [100/224], Loss: 0.0018\n",
      "Epoch [330/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [331/500], lter [100/224], Loss: 0.0013\n",
      "Epoch [331/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [332/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [332/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [333/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [333/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [334/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [334/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [335/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [335/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [336/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [336/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [337/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [337/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [338/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [338/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [339/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [339/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [340/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [340/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [341/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [341/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [342/500], lter [100/224], Loss: 0.0010\n",
      "Epoch [342/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [343/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [343/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [344/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [344/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [345/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [345/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [346/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [346/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [347/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [347/500], lter [200/224], Loss: 0.0227\n",
      "Epoch [348/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [348/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [349/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [349/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [350/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [350/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [351/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [351/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [352/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [352/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [353/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [353/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [354/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [354/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [355/500], lter [100/224], Loss: 0.0000\n",
      "Epoch [355/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [356/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [356/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [357/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [357/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [358/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [358/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [359/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [359/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [360/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [360/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [361/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [361/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [362/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [362/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [363/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [363/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [364/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [364/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [365/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [365/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [366/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [366/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [367/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [367/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [368/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [368/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [369/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [369/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [370/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [370/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [371/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [371/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [372/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [372/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [373/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [373/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [374/500], lter [100/224], Loss: 0.0008\n",
      "Epoch [374/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [375/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [375/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [376/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [376/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [377/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [377/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [378/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [378/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [379/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [379/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [380/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [380/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [381/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [381/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [382/500], lter [100/224], Loss: 0.0009\n",
      "Epoch [382/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [383/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [383/500], lter [200/224], Loss: 0.0014\n",
      "Epoch [384/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [384/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [385/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [385/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [386/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [386/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [387/500], lter [100/224], Loss: 0.0009\n",
      "Epoch [387/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [388/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [388/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [389/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [389/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [390/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [390/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [391/500], lter [100/224], Loss: 0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [391/500], lter [200/224], Loss: 0.0000\n",
      "Epoch [392/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [392/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [393/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [393/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [394/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [394/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [395/500], lter [100/224], Loss: 0.0011\n",
      "Epoch [395/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [396/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [396/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [397/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [397/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [398/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [398/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [399/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [399/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [400/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [400/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [401/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [401/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [402/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [402/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [403/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [403/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [404/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [404/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [420/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [420/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [421/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [421/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [422/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [422/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [423/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [423/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [424/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [424/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [425/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [425/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [426/500], lter [100/224], Loss: 0.0011\n",
      "Epoch [426/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [427/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [427/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [428/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [428/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [429/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [429/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [430/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [430/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [431/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [431/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [432/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [432/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [433/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [433/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [434/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [434/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [435/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [435/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [436/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [436/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [437/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [437/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [438/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [438/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [439/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [439/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [440/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [440/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [441/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [441/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [442/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [442/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [443/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [443/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [444/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [444/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [445/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [445/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [446/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [446/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [447/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [447/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [448/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [448/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [449/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [449/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [450/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [450/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [451/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [451/500], lter [200/224], Loss: 0.0008\n",
      "Epoch [452/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [452/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [453/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [453/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [454/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [454/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [455/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [455/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [456/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [456/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [457/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [457/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [458/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [458/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [459/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [459/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [460/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [460/500], lter [200/224], Loss: 0.0273\n",
      "Epoch [461/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [461/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [462/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [462/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [463/500], lter [100/224], Loss: 0.0000\n",
      "Epoch [463/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [464/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [464/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [465/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [465/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [466/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [466/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [467/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [467/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [468/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [468/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [469/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [469/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [470/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [470/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [471/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [471/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [472/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [472/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [473/500], lter [100/224], Loss: 0.0007\n",
      "Epoch [473/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [474/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [474/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [475/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [475/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [476/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [476/500], lter [200/224], Loss: 0.0007\n",
      "Epoch [477/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [477/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [478/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [478/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [479/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [479/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [480/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [480/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [481/500], lter [100/224], Loss: 0.0005\n",
      "Epoch [481/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [482/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [482/500], lter [200/224], Loss: 0.0006\n",
      "Epoch [483/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [483/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [484/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [484/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [485/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [485/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [486/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [486/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [487/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [487/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [488/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [488/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [489/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [489/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [490/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [490/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [491/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [491/500], lter [200/224], Loss: 0.0004\n",
      "Epoch [492/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [492/500], lter [200/224], Loss: 0.0002\n",
      "Epoch [493/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [493/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [494/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [494/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [495/500], lter [100/224], Loss: 0.0003\n",
      "Epoch [495/500], lter [200/224], Loss: 0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [496/500], lter [100/224], Loss: 0.0001\n",
      "Epoch [496/500], lter [200/224], Loss: 0.0003\n",
      "Epoch [497/500], lter [100/224], Loss: 0.0004\n",
      "Epoch [497/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [498/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [498/500], lter [200/224], Loss: 0.0005\n",
      "Epoch [499/500], lter [100/224], Loss: 0.0006\n",
      "Epoch [499/500], lter [200/224], Loss: 0.0001\n",
      "Epoch [500/500], lter [100/224], Loss: 0.0002\n",
      "Epoch [500/500], lter [200/224], Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "\n",
    "        X = batch_images.cuda()\n",
    "        Y = batch_labels.cuda()\n",
    "\n",
    "        pre = model(X)\n",
    "        cost = loss(pre, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, train_num//batch_size, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T04:17:20.127850Z",
     "start_time": "2019-01-21T04:17:17.546087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test images: 96.464286 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    \n",
    "    images = images.cuda()\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "    \n",
    "print('Accuracy of test images: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "110px",
    "width": "253px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "365px",
    "left": "1563px",
    "right": "20px",
    "top": "117px",
    "width": "347px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
