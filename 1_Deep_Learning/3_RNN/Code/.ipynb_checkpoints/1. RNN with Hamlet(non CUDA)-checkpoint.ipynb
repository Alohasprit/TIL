{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19. RNN with Hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import nltk\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.1 Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/hoyounson/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"gutenberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Hamlet by William Shakespeare 1599]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Enter Barnardo and Francisco two Centinels.\n",
      "\n",
      "  Barnardo. Who's there?\n",
      "  Fran. Nay answer me: Stand & vnfold\n",
      "your selfe\n",
      "\n",
      "   Bar. Long liue the King\n",
      "\n",
      "   Fran. Barnardo?\n",
      "  Bar. He\n",
      "\n",
      "   Fran. You come most carefully vpon your houre\n",
      "\n",
      "   Bar. 'Tis now strook twelue, get thee to bed Francisco\n",
      "\n",
      "   Fran. For this releefe much thankes: 'Tis bitter cold,\n",
      "And I am sicke at heart\n",
      "\n",
      "   Barn. Haue you had quiet Guard?\n",
      "  Fran. Not\n"
     ]
    }
   ],
   "source": [
    "raw = nltk.corpus.gutenberg.raw(\"shakespeare-hamlet.txt\")\n",
    "print(raw[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.2 Char to Dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {}\n",
    "index2char = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in raw :\n",
    "    if char not in char2index.keys() :\n",
    "        char2index[char] = len(char2index)\n",
    "        index2char.append(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[': 0,\n",
       " 'T': 1,\n",
       " 'h': 2,\n",
       " 'e': 3,\n",
       " ' ': 4,\n",
       " 'r': 5,\n",
       " 'a': 6,\n",
       " 'g': 7,\n",
       " 'd': 8,\n",
       " 'i': 9,\n",
       " 'o': 10,\n",
       " 'f': 11,\n",
       " 'H': 12,\n",
       " 'm': 13,\n",
       " 'l': 14,\n",
       " 't': 15,\n",
       " 'b': 16,\n",
       " 'y': 17,\n",
       " 'W': 18,\n",
       " 'S': 19,\n",
       " 'k': 20,\n",
       " 's': 21,\n",
       " 'p': 22,\n",
       " '1': 23,\n",
       " '5': 24,\n",
       " '9': 25,\n",
       " ']': 26,\n",
       " '\\n': 27,\n",
       " 'A': 28,\n",
       " 'c': 29,\n",
       " 'u': 30,\n",
       " 'P': 31,\n",
       " '.': 32,\n",
       " 'n': 33,\n",
       " 'E': 34,\n",
       " 'B': 35,\n",
       " 'F': 36,\n",
       " 'w': 37,\n",
       " 'C': 38,\n",
       " \"'\": 39,\n",
       " '?': 40,\n",
       " 'N': 41,\n",
       " ':': 42,\n",
       " '&': 43,\n",
       " 'v': 44,\n",
       " 'L': 45,\n",
       " 'K': 46,\n",
       " 'Y': 47,\n",
       " ',': 48,\n",
       " 'I': 49,\n",
       " 'q': 50,\n",
       " 'G': 51,\n",
       " 'M': 52,\n",
       " 'R': 53,\n",
       " '-': 54,\n",
       " 'D': 55,\n",
       " 'O': 56,\n",
       " 'x': 57,\n",
       " ';': 58,\n",
       " 'Q': 59,\n",
       " 'z': 60,\n",
       " '(': 61,\n",
       " ')': 62,\n",
       " 'V': 63,\n",
       " '!': 64,\n",
       " 'j': 65,\n",
       " 'Z': 66}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of input & output : 67\n"
     ]
    }
   ],
   "source": [
    "dim = len(char2index)\n",
    "print(\"Dimension of input & output :\", dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2vec = {}\n",
    "#eye : 행렬에서 대각선만 1인 정뱡행렬 -> one-hot encoding때 사용함\n",
    "eye = np.eye(len(char2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in char2index.keys() :\n",
    "    char2vec[item] = eye[char2index[item],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2vec['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([char2vec[char] for char in raw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.3 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/nn.html#torch.nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\t\n",
    "# input_size – The number of expected features in the input x\n",
    "# hidden_size – The number of features in the hidden state h\n",
    "# num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
    "# nonlinearity – The non-linearity to use. Can be either ‘tanh’ or ‘relu’. Default: ‘tanh’\n",
    "# bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "# batch_first – If True, then the input and output tensors are provided as (batch, seq, feature). Default: False\n",
    "# dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "# bidirectional – If True, becomes a bidirectional RNN. Default: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        out, hidden = self.rnn(input, hidden)\n",
    "        fc_out = self.fc(out)\n",
    "        return fc_out, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(dim, 500, dim, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.4 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Iter [100/1627] Loss: 324.2513\n",
      "Epoch [1/5], Iter [200/1627] Loss: 305.7499\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6c71f2be81eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    sp = list(range(0, len(data) - 2 * seq_len, seq_len))\n",
    "    sp = np.add(sp, random.randint(0, seq_len))\n",
    "    random.shuffle(sp)\n",
    "    \n",
    "    for i in range(len(sp)) :\n",
    "    \n",
    "        hidden = model.init_hidden()\n",
    "\n",
    "        cost = 0\n",
    "            \n",
    "        for pos in range(sp[i], sp[i] + seq_len):\n",
    "            \n",
    "            X = torch.from_numpy(data[pos]).type(torch.FloatTensor).reshape(1, 1, dim)\n",
    "            y = torch.from_numpy(data[pos+1])\n",
    "            \n",
    "            _, y = y.max(dim=0)\n",
    "            \n",
    "            pre, hidden = model(X,hidden)\n",
    "            cost += loss(pre.reshape(1, dim), y.reshape(1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0 :\n",
    "            print('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n",
    "                     %(epoch+1, num_epochs, i + 1, len(sp), cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.5 Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Generated Text : \n",
      "\n",
      " rhis and than the King of your the Sondersone then\n",
      "I sour to the framation\n",
      "\n",
      "   Obh. It the be a pertoue,\n",
      "With shour for a doofe then\n",
      "\n",
      "  Han. I all with'r hest nene the King. Growes\n",
      "\n",
      "   Rang. To the fron trent ther frome, the verit whinge and to the King of Horound.\n",
      "\n",
      "Exhur to to to the Connten,\n",
      "We dow to to's mode in the the to hant\n",
      "\n",
      "   Ham. An shat soue for tre fortirn will thon ter this and fron trentent the thoue a frele of a seruld my Lord to bus in the Sonning to might\n",
      "\n",
      "   Hor. Sin to't and a\n"
     ]
    }
   ],
   "source": [
    "start_num = 5\n",
    "text = index2char[start_num]\n",
    "\n",
    "model.eval()\n",
    "hidden = model.init_hidden()\n",
    "\n",
    "X_test = torch.from_numpy(data[start_num]).type(torch.FloatTensor).cuda().reshape(1, 1, dim)\n",
    "    \n",
    "for i in range(500) :\n",
    "\n",
    "    pre, hidden = model(X_test, hidden)\n",
    "\n",
    "    temp = pre.reshape(-1).cpu().data.numpy()\n",
    "\n",
    "    best_5 = np.argsort(temp)[::-1][:5]\n",
    "    \n",
    "    temp = np.exp(temp[best_5])\n",
    "    \n",
    "    temp = temp / temp.sum()\n",
    "    \n",
    "    pre = np.random.choice(best_5, 1, p = temp)[0]\n",
    "    \n",
    "    curr_char = index2char[pre]\n",
    "    \n",
    "    text += curr_char\n",
    "    \n",
    "    X_test = torch.from_numpy(char2vec[curr_char]).type(torch.FloatTensor).reshape(1, 1, dim)\n",
    "    \n",
    "print(\"* Generated Text : \\n\\n\", text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
