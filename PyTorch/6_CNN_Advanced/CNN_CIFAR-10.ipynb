{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1 Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2 Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "lr = 0.0002\n",
    "num_epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train = dset.CIFAR10(\"./\", train=True, transform = transforms.ToTensor(),target_transform=None, download=True)\n",
    "test = dset.CIFAR10(\"./\", train=False, transform = transforms.ToTensor(),target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__getitem__(0)[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.2314,  0.1686,  0.1961,  ...,  0.6196,  0.5961,  0.5804],\n",
       "          [ 0.0627,  0.0000,  0.0706,  ...,  0.4824,  0.4667,  0.4784],\n",
       "          [ 0.0980,  0.0627,  0.1922,  ...,  0.4627,  0.4706,  0.4275],\n",
       "          ...,\n",
       "          [ 0.8157,  0.7882,  0.7765,  ...,  0.6275,  0.2196,  0.2078],\n",
       "          [ 0.7059,  0.6784,  0.7294,  ...,  0.7216,  0.3804,  0.3255],\n",
       "          [ 0.6941,  0.6588,  0.7020,  ...,  0.8471,  0.5922,  0.4824]],\n",
       " \n",
       "         [[ 0.2431,  0.1804,  0.1882,  ...,  0.5176,  0.4902,  0.4863],\n",
       "          [ 0.0784,  0.0000,  0.0314,  ...,  0.3451,  0.3255,  0.3412],\n",
       "          [ 0.0941,  0.0275,  0.1059,  ...,  0.3294,  0.3294,  0.2863],\n",
       "          ...,\n",
       "          [ 0.6667,  0.6000,  0.6314,  ...,  0.5216,  0.1216,  0.1333],\n",
       "          [ 0.5451,  0.4824,  0.5647,  ...,  0.5804,  0.2431,  0.2078],\n",
       "          [ 0.5647,  0.5059,  0.5569,  ...,  0.7216,  0.4627,  0.3608]],\n",
       " \n",
       "         [[ 0.2471,  0.1765,  0.1686,  ...,  0.4235,  0.4000,  0.4039],\n",
       "          [ 0.0784,  0.0000,  0.0000,  ...,  0.2157,  0.1961,  0.2235],\n",
       "          [ 0.0824,  0.0000,  0.0314,  ...,  0.1961,  0.1961,  0.1647],\n",
       "          ...,\n",
       "          [ 0.3765,  0.1333,  0.1020,  ...,  0.2745,  0.0275,  0.0784],\n",
       "          [ 0.3765,  0.1647,  0.1176,  ...,  0.3686,  0.1333,  0.1333],\n",
       "          [ 0.4549,  0.3686,  0.3412,  ...,  0.5490,  0.3294,  0.2824]]]), 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3 Set DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(3,16,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), #(32,16,16)\n",
    "            \n",
    "            nn.Conv2d(32,64,3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,128,3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),   #(128, 8,8)\n",
    "            \n",
    "            nn.Conv2d(128,256,3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256,256,3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),   #(256, 4,4)\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(256*4*4, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200,10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.fc_layer(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2 Loss func & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3 Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model restored\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = torch.load('./CIFAR10_model.pkl')\n",
    "    print(\"model restored\")\n",
    "except:\n",
    "    print(\"model not restored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 tensor(1.3855)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 tensor(1.3253)\n",
      "1 0 tensor(1.5367)\n",
      "1 100 tensor(1.4549)\n",
      "2 0 tensor(1.3612)\n",
      "2 100 tensor(1.4731)\n",
      "3 0 tensor(1.5061)\n",
      "3 100 tensor(1.4010)\n",
      "4 0 tensor(1.4535)\n",
      "4 100 tensor(1.3351)\n",
      "5 0 tensor(1.3250)\n",
      "5 100 tensor(1.4530)\n",
      "6 0 tensor(1.4642)\n",
      "6 100 tensor(1.4642)\n",
      "7 0 tensor(1.4662)\n",
      "7 100 tensor(1.4469)\n",
      "8 0 tensor(1.5437)\n",
      "8 100 tensor(1.3625)\n",
      "9 0 tensor(1.4220)\n",
      "9 100 tensor(1.4001)\n",
      "10 0 tensor(1.5615)\n",
      "10 100 tensor(1.4821)\n",
      "11 0 tensor(1.3484)\n",
      "11 100 tensor(1.4942)\n",
      "12 0 tensor(1.4756)\n",
      "12 100 tensor(1.2858)\n",
      "13 0 tensor(1.4096)\n",
      "13 100 tensor(1.3746)\n",
      "14 0 tensor(1.3826)\n",
      "14 100 tensor(1.5361)\n",
      "15 0 tensor(1.5005)\n",
      "15 100 tensor(1.4388)\n",
      "16 0 tensor(1.4022)\n",
      "16 100 tensor(1.4055)\n",
      "17 0 tensor(1.3836)\n",
      "17 100 tensor(1.4204)\n",
      "18 0 tensor(1.3506)\n",
      "18 100 tensor(1.5217)\n",
      "19 0 tensor(1.3710)\n",
      "19 100 tensor(1.5463)\n",
      "20 0 tensor(1.3696)\n",
      "20 100 tensor(1.3651)\n",
      "21 0 tensor(1.3713)\n",
      "21 100 tensor(1.3807)\n",
      "22 0 tensor(1.4029)\n",
      "22 100 tensor(1.3351)\n",
      "23 0 tensor(1.4733)\n",
      "23 100 tensor(1.4393)\n",
      "24 0 tensor(1.4922)\n",
      "24 100 tensor(1.4921)\n",
      "25 0 tensor(1.4324)\n",
      "25 100 tensor(1.4537)\n",
      "26 0 tensor(1.4181)\n",
      "26 100 tensor(1.4620)\n",
      "27 0 tensor(1.3089)\n",
      "27 100 tensor(1.4101)\n",
      "28 0 tensor(1.4398)\n",
      "28 100 tensor(1.3114)\n",
      "29 0 tensor(1.5200)\n",
      "29 100 tensor(1.5038)\n",
      "30 0 tensor(1.5450)\n",
      "30 100 tensor(1.4372)\n",
      "31 0 tensor(1.4280)\n",
      "31 100 tensor(1.4179)\n",
      "32 0 tensor(1.4072)\n",
      "32 100 tensor(1.3379)\n",
      "33 0 tensor(1.4616)\n",
      "33 100 tensor(1.3859)\n",
      "34 0 tensor(1.4648)\n",
      "34 100 tensor(1.5495)\n",
      "35 0 tensor(1.5038)\n",
      "35 100 tensor(1.3447)\n",
      "36 0 tensor(1.4354)\n",
      "36 100 tensor(1.4189)\n",
      "37 0 tensor(1.3851)\n",
      "37 100 tensor(1.4913)\n",
      "38 0 tensor(1.4197)\n",
      "38 100 tensor(1.4687)\n",
      "39 0 tensor(1.3427)\n",
      "39 100 tensor(1.4380)\n",
      "40 0 tensor(1.5794)\n",
      "40 100 tensor(1.3894)\n",
      "41 0 tensor(1.3473)\n",
      "41 100 tensor(1.3866)\n",
      "42 0 tensor(1.5123)\n",
      "42 100 tensor(1.4535)\n",
      "43 0 tensor(1.4241)\n",
      "43 100 tensor(1.3742)\n",
      "44 0 tensor(1.3329)\n",
      "44 100 tensor(1.4709)\n",
      "45 0 tensor(1.5233)\n",
      "45 100 tensor(1.3666)\n",
      "46 0 tensor(1.3682)\n",
      "46 100 tensor(1.4763)\n",
      "47 0 tensor(1.3932)\n",
      "47 100 tensor(1.4850)\n",
      "48 0 tensor(1.4052)\n",
      "48 100 tensor(1.3773)\n",
      "49 0 tensor(1.4144)\n",
      "49 100 tensor(1.4421)\n",
      "50 0 tensor(1.3910)\n",
      "50 100 tensor(1.4484)\n",
      "51 0 tensor(1.3865)\n",
      "51 100 tensor(1.4601)\n",
      "52 0 tensor(1.4649)\n",
      "52 100 tensor(1.5636)\n",
      "53 0 tensor(1.3946)\n",
      "53 100 tensor(1.4743)\n",
      "54 0 tensor(1.4267)\n",
      "54 100 tensor(1.3732)\n",
      "55 0 tensor(1.4369)\n",
      "55 100 tensor(1.3358)\n",
      "56 0 tensor(1.3665)\n",
      "56 100 tensor(1.3754)\n",
      "57 0 tensor(1.3482)\n",
      "57 100 tensor(1.4592)\n",
      "58 0 tensor(1.4531)\n",
      "58 100 tensor(1.3761)\n",
      "59 0 tensor(1.5539)\n",
      "59 100 tensor(1.3004)\n",
      "60 0 tensor(1.2730)\n",
      "60 100 tensor(1.3673)\n",
      "61 0 tensor(1.3939)\n",
      "61 100 tensor(1.4144)\n",
      "62 0 tensor(1.3266)\n",
      "62 100 tensor(1.3763)\n",
      "63 0 tensor(1.4516)\n",
      "63 100 tensor(1.4143)\n",
      "64 0 tensor(1.4312)\n",
      "64 100 tensor(1.4001)\n",
      "65 0 tensor(1.3942)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(images)\n",
    "        loss=loss_func(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(epoch, i, loss)\n",
    "            torch.save(model, './CIFAR10_model.pkl')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images, volatile=True)\n",
    "    labels = Variable(labels)\n",
    "    \n",
    "    output = model.(images)\n",
    "    _,output_index = torch.max(output, 1)\n",
    "    \n",
    "    total += label.size(0)\n",
    "    correct += (output_index ==labels).sum().float()\n",
    "    \n",
    "print(\"Accuracy of Test Data:{}\" .format(100*correct/total))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
